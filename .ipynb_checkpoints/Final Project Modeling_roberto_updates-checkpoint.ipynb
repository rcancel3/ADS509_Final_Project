{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation / Descriptive Statistics Notebook\n",
    "## ADS 509 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### UTILITIES\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "#### PREPROCESSING\n",
    "import nltk\n",
    "import regex as re\n",
    "import emoji\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from emoji import is_emoji\n",
    "\n",
    "#### CLASSIFIERS\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "\n",
    "#### TOPIC MODELING\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "#from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Import .csv to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disney.csv', 'hbo-max-stream-tv-movies.csv', 'hulu-stream-shows-movies.csv', 'netflix.csv', 'youtube-watch-listen-stream.csv']\n"
     ]
    }
   ],
   "source": [
    "def follower_import(filenum):\n",
    "    svs = pd.DataFrame()\n",
    "    raw_file = os.listdir('Data')[filenum] # changed to 'Data' folder\n",
    "    file = ('Data/'+ raw_file) # changed to 'Data' folder\n",
    "    print(file)\n",
    "    \n",
    "    svs = pd.read_csv(file, header=0)\n",
    "    svs['review'] = svs['review'].apply(str)\n",
    "    svs['title'] = svs['title'].apply(str)\n",
    "    svs['app_name'] = svs['app_name'].apply(str)\n",
    "    \n",
    "    svs.drop(svs[svs['review'] == 'nan'].index, inplace = True)\n",
    "    svs.drop(svs[svs['review'] == ''].index, inplace = True)\n",
    "    svs.drop(svs[svs['title'] == 'nan'].index, inplace = True)\n",
    "    svs.drop(svs[svs['title'] == ''].index, inplace = True)\n",
    "    svs.drop(svs[svs['app_name'] == 'nan'].index, inplace = True)\n",
    "    svs.drop(svs[svs['app_name'] == ''].index, inplace = True)\n",
    "    \n",
    "    #svs['desc_len'] = svs['desc'].str.len()\n",
    "    return svs\n",
    "\n",
    "print(os.listdir('Data'))  # changed to 'Data' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/disney.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1008 entries, 0 to 1007\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   app_name  1008 non-null   object\n",
      " 1   title     1008 non-null   object\n",
      " 2   review    1008 non-null   object\n",
      " 3   rating    1008 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 79.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disney</td>\n",
       "      <td>MISSING many shows (and languages)</td>\n",
       "      <td>I grew up watching many a Disney shows. Signed...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disney</td>\n",
       "      <td>really quite upset</td>\n",
       "      <td>pretty sure this was deliberate. my old iphone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disney</td>\n",
       "      <td>Probably the worst streaming app.</td>\n",
       "      <td>We have just about every streaming app you can...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  app_name                               title  \\\n",
       "0   disney  MISSING many shows (and languages)   \n",
       "1   disney                  really quite upset   \n",
       "2   disney   Probably the worst streaming app.   \n",
       "\n",
       "                                              review  rating  \n",
       "0  I grew up watching many a Disney shows. Signed...       3  \n",
       "1  pretty sure this was deliberate. my old iphone...       1  \n",
       "2  We have just about every streaming app you can...       3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disney_dl = follower_import(0)\n",
    "disney = disney_dl[['app_name', 'title', 'review', 'rating']]\n",
    "disney.describe().T\n",
    "print(disney.info())\n",
    "disney.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import hbomax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/hbo-max-stream-tv-movies.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1001 entries, 0 to 1000\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   app_name  1001 non-null   object\n",
      " 1   title     1001 non-null   object\n",
      " 2   review    1001 non-null   object\n",
      " 3   rating    1001 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 79.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hbo-max-stream-tv-movies</td>\n",
       "      <td>HBO Enforces Mandatory Letterboxing for ‚ÄúCoNsI...</td>\n",
       "      <td>EDIT: Freedom to watch content in preferred as...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hbo-max-stream-tv-movies</td>\n",
       "      <td>Great movies terrible app</td>\n",
       "      <td>I love the amount of shows and movies HBO Max ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hbo-max-stream-tv-movies</td>\n",
       "      <td>Buggy, slow, poorly designed, screen-waster</td>\n",
       "      <td>Got a decent size iPhone? Good thing, cause th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   app_name  \\\n",
       "0  hbo-max-stream-tv-movies   \n",
       "1  hbo-max-stream-tv-movies   \n",
       "2  hbo-max-stream-tv-movies   \n",
       "\n",
       "                                               title  \\\n",
       "0  HBO Enforces Mandatory Letterboxing for ‚ÄúCoNsI...   \n",
       "1                          Great movies terrible app   \n",
       "2        Buggy, slow, poorly designed, screen-waster   \n",
       "\n",
       "                                              review  rating  \n",
       "0  EDIT: Freedom to watch content in preferred as...       5  \n",
       "1  I love the amount of shows and movies HBO Max ...       2  \n",
       "2  Got a decent size iPhone? Good thing, cause th...       2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbomax_dl = follower_import(1)\n",
    "hbomax = hbomax_dl[['app_name', 'title', 'review', 'rating']]\n",
    "hbomax.describe().T\n",
    "print(hbomax.info())\n",
    "hbomax.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import hulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/hulu-stream-shows-movies.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   app_name  1000 non-null   object\n",
      " 1   title     1000 non-null   object\n",
      " 2   review    1000 non-null   object\n",
      " 3   rating    1000 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 79.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hulu-stream-shows-movies</td>\n",
       "      <td>Magnificent, better than tinder</td>\n",
       "      <td>I haven‚Äôt felt more alive in YEARS!! My wife l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hulu-stream-shows-movies</td>\n",
       "      <td>Ughhh</td>\n",
       "      <td>When you turn your phone upright you see your ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hulu-stream-shows-movies</td>\n",
       "      <td>Good but casting is flawed</td>\n",
       "      <td>I‚Äôve noticed some major flaws when casting sho...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   app_name                            title  \\\n",
       "0  hulu-stream-shows-movies  Magnificent, better than tinder   \n",
       "1  hulu-stream-shows-movies                            Ughhh   \n",
       "2  hulu-stream-shows-movies       Good but casting is flawed   \n",
       "\n",
       "                                              review  rating  \n",
       "0  I haven‚Äôt felt more alive in YEARS!! My wife l...       5  \n",
       "1  When you turn your phone upright you see your ...       3  \n",
       "2  I‚Äôve noticed some major flaws when casting sho...       2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hulu_dl = follower_import(2)\n",
    "hulu = hulu_dl[['app_name', 'title', 'review', 'rating']]\n",
    "hulu.describe().T\n",
    "print(hulu.info())\n",
    "hulu.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/netflix.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1004 entries, 0 to 1003\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   app_name  1004 non-null   object\n",
      " 1   title     1004 non-null   object\n",
      " 2   review    1004 non-null   object\n",
      " 3   rating    1004 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 79.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netflix</td>\n",
       "      <td>Great app</td>\n",
       "      <td>I‚Äôve been using Netflix for 5 years and now I\\...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>netflix</td>\n",
       "      <td>Its amazing but needs to be better</td>\n",
       "      <td>I‚Äôve been using Netflix for 5 years and now I'...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netflix</td>\n",
       "      <td>Trash</td>\n",
       "      <td>I use a VPN to protect my privacy and the app ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  app_name                               title  \\\n",
       "0  netflix                           Great app   \n",
       "1  netflix  Its amazing but needs to be better   \n",
       "2  netflix                               Trash   \n",
       "\n",
       "                                              review  rating  \n",
       "0  I‚Äôve been using Netflix for 5 years and now I\\...       4  \n",
       "1  I‚Äôve been using Netflix for 5 years and now I'...       4  \n",
       "2  I use a VPN to protect my privacy and the app ...       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_dl = follower_import(3)\n",
    "netflix = netflix_dl[['app_name', 'title', 'review', 'rating']]\n",
    "netflix.describe().T\n",
    "print(netflix.info())\n",
    "netflix.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/youtube-watch-listen-stream.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1019 entries, 0 to 1018\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   app_name  1019 non-null   object\n",
      " 1   title     1019 non-null   object\n",
      " 2   review    1019 non-null   object\n",
      " 3   rating    1019 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 79.8+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube-watch-listen-stream</td>\n",
       "      <td>Great review thank you</td>\n",
       "      <td>Well explained I‚Äôve been using all the topaz l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youtube-watch-listen-stream</td>\n",
       "      <td>Same videos keep showing up in loop and made f...</td>\n",
       "      <td>Update (October 1,2022): the issue with the ol...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube-watch-listen-stream</td>\n",
       "      <td>Comments, ads, restrictions.</td>\n",
       "      <td>If the video goes into an ad then I lose my sp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      app_name  \\\n",
       "0  youtube-watch-listen-stream   \n",
       "1  youtube-watch-listen-stream   \n",
       "2  youtube-watch-listen-stream   \n",
       "\n",
       "                                               title  \\\n",
       "0                             Great review thank you   \n",
       "1  Same videos keep showing up in loop and made f...   \n",
       "2                       Comments, ads, restrictions.   \n",
       "\n",
       "                                              review  rating  \n",
       "0  Well explained I‚Äôve been using all the topaz l...       5  \n",
       "1  Update (October 1,2022): the issue with the ol...       4  \n",
       "2  If the video goes into an ad then I lose my sp...       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_dl = follower_import(4)\n",
    "youtube = youtube_dl[['app_name', 'title', 'review', 'rating']]\n",
    "youtube.describe().T\n",
    "print(youtube.info())\n",
    "youtube.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disney</td>\n",
       "      <td>MISSING many shows (and languages)</td>\n",
       "      <td>I grew up watching many a Disney shows. Signed...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disney</td>\n",
       "      <td>really quite upset</td>\n",
       "      <td>pretty sure this was deliberate. my old iphone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disney</td>\n",
       "      <td>Probably the worst streaming app.</td>\n",
       "      <td>We have just about every streaming app you can...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disney</td>\n",
       "      <td>Love it but could add more stuff</td>\n",
       "      <td>I live Disney! I grew up with it my whole life...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disney</td>\n",
       "      <td>Frequently causes issues with connectivity</td>\n",
       "      <td>App works great through non-iOS devices but lo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>By one concern at this time, once you open you...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Easy on the ads !!!!</td>\n",
       "      <td>Take it easy on the ads Google ! I get it that...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>youtube</td>\n",
       "      <td>You tube outstanding in information dessimination</td>\n",
       "      <td>You tube is outstanding in bringing out idiffe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>youtube</td>\n",
       "      <td>It is great for maybe you but for me.</td>\n",
       "      <td>I live somewhere close to the mountains in Cov...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Horrible landscape experience</td>\n",
       "      <td>Revert the horrible change you made to how com...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5032 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_name                                              title  \\\n",
       "0      disney                 MISSING many shows (and languages)   \n",
       "1      disney                                 really quite upset   \n",
       "2      disney                  Probably the worst streaming app.   \n",
       "3      disney                   Love it but could add more stuff   \n",
       "4      disney         Frequently causes issues with connectivity   \n",
       "...       ...                                                ...   \n",
       "5027  youtube                                          Wonderful   \n",
       "5028  youtube                               Easy on the ads !!!!   \n",
       "5029  youtube  You tube outstanding in information dessimination   \n",
       "5030  youtube              It is great for maybe you but for me.   \n",
       "5031  youtube                      Horrible landscape experience   \n",
       "\n",
       "                                                 review  rating  \n",
       "0     I grew up watching many a Disney shows. Signed...       3  \n",
       "1     pretty sure this was deliberate. my old iphone...       1  \n",
       "2     We have just about every streaming app you can...       3  \n",
       "3     I live Disney! I grew up with it my whole life...       4  \n",
       "4     App works great through non-iOS devices but lo...       2  \n",
       "...                                                 ...     ...  \n",
       "5027  By one concern at this time, once you open you...       4  \n",
       "5028  Take it easy on the ads Google ! I get it that...       1  \n",
       "5029  You tube is outstanding in bringing out idiffe...       5  \n",
       "5030  I live somewhere close to the mountains in Cov...       5  \n",
       "5031  Revert the horrible change you made to how com...       2  \n",
       "\n",
       "[5032 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C:\\Users\\rober\\OneDrive - University of San Diego\\Documents\\GitHub\\ADS509_Final_Project            'youtube-watch-listen-stream': 'youtube'}})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Stopword List(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = []\n",
    "sw.extend(stopwords.words([\"english\"]))\n",
    "sw.extend((\"disney\", \"disney+\", \"disneyplus\", \"plus\", \"hbomax\", \"hbo\", \"max\", \"hulu\", \"netflix\", \"youtube\", \"tube\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Preprocess Cells into Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_words(x):\n",
    "    x = re.sub('[^a-z\\s]', '', x.lower())\n",
    "    x = [w for w in x.split() if w not in set(sw)]\n",
    "    # USE THIS ONE FOR TOKENS\n",
    "    return x\n",
    "    # USE THIS ONE FOR STRING\n",
    "    #return ' '.join(x)\n",
    "    \n",
    "# Write function to leave hashtags, emojis, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Text Columns into New Token Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_onlywords</th>\n",
       "      <th>title_onlywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>By one concern at this time, once you open you...</td>\n",
       "      <td>4</td>\n",
       "      <td>[one, concern, time, open, queue, see, somethi...</td>\n",
       "      <td>[wonderful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Easy on the ads !!!!</td>\n",
       "      <td>Take it easy on the ads Google ! I get it that...</td>\n",
       "      <td>1</td>\n",
       "      <td>[take, easy, ads, google, get, free, service, ...</td>\n",
       "      <td>[easy, ads]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>youtube</td>\n",
       "      <td>You tube outstanding in information dessimination</td>\n",
       "      <td>You tube is outstanding in bringing out idiffe...</td>\n",
       "      <td>5</td>\n",
       "      <td>[outstanding, bringing, idifferent, point, vie...</td>\n",
       "      <td>[outstanding, information, dessimination]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>youtube</td>\n",
       "      <td>It is great for maybe you but for me.</td>\n",
       "      <td>I live somewhere close to the mountains in Cov...</td>\n",
       "      <td>5</td>\n",
       "      <td>[live, somewhere, close, mountains, cove, ariz...</td>\n",
       "      <td>[great, maybe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Horrible landscape experience</td>\n",
       "      <td>Revert the horrible change you made to how com...</td>\n",
       "      <td>2</td>\n",
       "      <td>[revert, horrible, change, made, commentsdescr...</td>\n",
       "      <td>[horrible, landscape, experience]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_name                                              title  \\\n",
       "5027  youtube                                          Wonderful   \n",
       "5028  youtube                               Easy on the ads !!!!   \n",
       "5029  youtube  You tube outstanding in information dessimination   \n",
       "5030  youtube              It is great for maybe you but for me.   \n",
       "5031  youtube                      Horrible landscape experience   \n",
       "\n",
       "                                                 review  rating  \\\n",
       "5027  By one concern at this time, once you open you...       4   \n",
       "5028  Take it easy on the ads Google ! I get it that...       1   \n",
       "5029  You tube is outstanding in bringing out idiffe...       5   \n",
       "5030  I live somewhere close to the mountains in Cov...       5   \n",
       "5031  Revert the horrible change you made to how com...       2   \n",
       "\n",
       "                                       review_onlywords  \\\n",
       "5027  [one, concern, time, open, queue, see, somethi...   \n",
       "5028  [take, easy, ads, google, get, free, service, ...   \n",
       "5029  [outstanding, bringing, idifferent, point, vie...   \n",
       "5030  [live, somewhere, close, mountains, cove, ariz...   \n",
       "5031  [revert, horrible, change, made, commentsdescr...   \n",
       "\n",
       "                                title_onlywords  \n",
       "5027                                [wonderful]  \n",
       "5028                                [easy, ads]  \n",
       "5029  [outstanding, information, dessimination]  \n",
       "5030                             [great, maybe]  \n",
       "5031          [horrible, landscape, experience]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_onlywords'] = df['review'].apply(only_words)\n",
    "df['title_onlywords'] = df['title'].apply(only_words)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Stats for DF Columns and Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(df_col, top_x_tokens = 20, verbose=True) :\n",
    "    counter = Counter()\n",
    "    df_col.map(counter.update)\n",
    "    num_tokens = sum(counter.values())\n",
    "    num_unique_tokens = len(counter.keys())\n",
    "    num_characters=0\n",
    "    for key, value in counter.items():\n",
    "        char = (len(key))*value\n",
    "        num_characters = num_characters + char\n",
    "    lexical_diversity = num_unique_tokens/num_tokens\n",
    "\n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        print(f\"The twenty most common tokens are:\")\n",
    "        print(counter.most_common(top_x_tokens))\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "\n",
    "def counter_descriptive_stats(counter, top_x_tokens = 20, verbose=True):    \n",
    "    #counter = Counter()\n",
    "    #df_col.map(counter.update)\n",
    "    num_tokens = sum(counter.values())\n",
    "    num_unique_tokens = len(counter.keys())\n",
    "    num_characters=0\n",
    "    for key, value in counter.items():\n",
    "        char = (len(key))*value\n",
    "        num_characters = num_characters + char\n",
    "    lexical_diversity = num_unique_tokens/num_tokens\n",
    "\n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        print(f\"The twenty most common tokens are:\")\n",
    "        print(counter.most_common(top_x_tokens))\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 182131 tokens in the data.\n",
      "There are 11289 unique tokens in the data.\n",
      "There are 1013276 characters in the data.\n",
      "The lexical diversity is 0.062 in the data.\n",
      "The twenty most common tokens are:\n",
      "[('app', 5020), ('watch', 2594), ('like', 2069), ('shows', 1860), ('im', 1446), ('get', 1404), ('show', 1373), ('dont', 1316), ('time', 1228), ('please', 1162), ('one', 1143), ('love', 1134), ('would', 1132), ('movies', 1113), ('even', 1087), ('cant', 989), ('good', 953), ('watching', 950), ('back', 937), ('video', 932)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[182131, 11289, 0.061982858491964575, 1013276]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats(df['review_onlywords'], top_x_tokens = 20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13677 tokens in the data.\n",
      "There are 2551 unique tokens in the data.\n",
      "There are 77084 characters in the data.\n",
      "The lexical diversity is 0.187 in the data.\n",
      "The twenty most common tokens are:\n",
      "[('app', 747), ('great', 296), ('good', 287), ('ads', 211), ('love', 186), ('please', 184), ('content', 157), ('shows', 132), ('work', 113), ('needs', 110), ('one', 107), ('read', 103), ('fix', 99), ('cant', 99), ('buggy', 98), ('many', 95), ('update', 95), ('terrible', 93), ('problem', 89), ('streaming', 88)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13677, 2551, 0.186517511150106, 77084]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats(df['title_onlywords'], top_x_tokens = 20, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üò° 82\n",
      "‚ù§ 79\n",
      "üòÅ 56\n",
      "üò≠ 54\n",
      "üëç 41\n",
      "üòä 30\n",
      "üôè 29\n",
      "üòÉ 27\n",
      "üèº 27\n",
      "üòç 25\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "df['review'].map(counter.update)\n",
    "num=0\n",
    "for key, value in counter.most_common():\n",
    "    if num <10:\n",
    "        if is_emoji(key) is True:\n",
    "            print(key, value)\n",
    "            num+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üò° 28\n",
      "‚ù§ 20\n",
      "üòÅ 16\n",
      "üëç 14\n",
      "üëé 12\n",
      "ü§¨ 11\n",
      "‚ö† 10\n",
      "‚≠ê 10\n",
      "üòç 9\n",
      "ü§© 8\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "df['title'].map(counter.update)\n",
    "num=0\n",
    "for key, value in counter.most_common():\n",
    "    if num <10:\n",
    "        if is_emoji(key) is True:\n",
    "            print(key, value)\n",
    "            num+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the 5 Streaming Corpora (Mainly from Mod 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the 5 Counters for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29985 tokens in the data.\n",
      "There are 4331 unique tokens in the data.\n",
      "There are 165067 characters in the data.\n",
      "The lexical diversity is 0.144 in the data.\n",
      "The twenty most common tokens are:\n",
      "[('app', 866), ('watch', 489), ('movies', 413), ('love', 388), ('like', 385), ('shows', 343), ('im', 238), ('would', 226), ('show', 213), ('dont', 210), ('get', 193), ('movie', 192), ('really', 189), ('please', 185), ('one', 181), ('good', 175), ('great', 172), ('watching', 169), ('tv', 160), ('cant', 157)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[29985, 4331, 0.14443888610972153, 165067]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disney = df[df['app_name'] == \"disney\"]\n",
    "disney_counter = Counter()\n",
    "disney['review_onlywords'].map(disney_counter.update)\n",
    "disney_num_tokens = sum(disney_counter.values())\n",
    "counter_descriptive_stats(disney_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 46524 tokens in the data.\n",
      "There are 4617 unique tokens in the data.\n",
      "There are 265180 characters in the data.\n",
      "The lexical diversity is 0.099 in the data.\n",
      "The twenty most common tokens are:\n",
      "[('app', 1989), ('watch', 633), ('content', 490), ('download', 399), ('time', 392), ('shows', 379), ('even', 366), ('get', 353), ('im', 339), ('like', 318), ('show', 304), ('streaming', 304), ('tv', 303), ('downloaded', 287), ('cant', 281), ('would', 260), ('one', 260), ('episode', 255), ('movies', 254), ('play', 254)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[46524, 4617, 0.09923910239876194, 265180]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbomax = df[df['app_name'] == \"hbomax\"]\n",
    "hbomax_counter = Counter()\n",
    "hbomax['review_onlywords'].map(hbomax_counter.update)\n",
    "hbomax_num_tokens = sum(hbomax_counter.values())\n",
    "counter_descriptive_stats(hbomax_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24466 tokens in the data.\n",
      "There are 3092 unique tokens in the data.\n",
      "There are 134173 characters in the data.\n",
      "The lexical diversity is 0.126 in the data.\n",
      "The twenty most common tokens are:\n",
      "[('app', 768), ('watch', 480), ('ads', 479), ('show', 335), ('shows', 268), ('get', 241), ('time', 206), ('im', 204), ('like', 198), ('even', 191), ('watching', 173), ('ad', 170), ('tv', 168), ('dont', 167), ('every', 165), ('episode', 162), ('cant', 157), ('play', 155), ('back', 150), ('fix', 141)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24466, 3092, 0.12637946538052808, 134173]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hulu = df[df['app_name'] == \"hulu\"]\n",
    "hulu_counter = Counter()\n",
    "hulu['review_onlywords'].map(hulu_counter.update)\n",
    "hulu_num_tokens = sum(hulu_counter.values())\n",
    "counter_descriptive_stats(hulu_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39421 tokens in the data.\n",
      "There are 4824 unique tokens in the data.\n",
      "There are 213863 characters in the data.\n",
      "The lexical diversity is 0.122 in the data.\n",
      "The twenty most common tokens are:\n",
      "[('shows', 831), ('like', 674), ('watch', 636), ('app', 629), ('please', 495), ('show', 447), ('dont', 394), ('good', 386), ('im', 370), ('movies', 367), ('love', 338), ('one', 307), ('really', 297), ('would', 292), ('get', 280), ('add', 265), ('back', 265), ('watching', 254), ('people', 244), ('want', 217)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[39421, 4824, 0.12237132492833769, 213863]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix = df[df['app_name'] == \"netflix\"]\n",
    "netflix_counter = Counter()\n",
    "netflix['review_onlywords'].map(netflix_counter.update)\n",
    "netflix_num_tokens = sum(netflix_counter.values())\n",
    "counter_descriptive_stats(netflix_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41735 tokens in the data.\n",
      "There are 5962 unique tokens in the data.\n",
      "There are 234993 characters in the data.\n",
      "The lexical diversity is 0.143 in the data.\n",
      "The twenty most common tokens are:\n",
      "[('app', 768), ('video', 728), ('videos', 620), ('like', 494), ('watch', 356), ('ads', 349), ('get', 337), ('dont', 315), ('im', 295), ('time', 261), ('one', 256), ('would', 250), ('want', 232), ('please', 231), ('see', 226), ('back', 224), ('also', 221), ('people', 216), ('even', 208), ('love', 207)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[41735, 5962, 0.14285371989936504, 234993]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube = df[df['app_name'] == \"youtube\"]\n",
    "youtube_counter = Counter()\n",
    "youtube['review_onlywords'].map(youtube_counter.update)\n",
    "youtube_num_tokens = sum(youtube_counter.values())\n",
    "counter_descriptive_stats(youtube_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Counters: Tokens Must Appear 3 Times in Every Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "disney_counter_2 = {key:value for (key, value) in disney_counter.items() if value >= 3}\n",
    "hbomax_counter_2 = {key:value for (key, value) in hbomax_counter.items() if value >= 3}\n",
    "hulu_counter_2 = {key:value for (key, value) in hulu_counter.items() if value >= 3}\n",
    "netflix_counter_2 = {key:value for (key, value) in netflix_counter.items() if value >= 3}\n",
    "youtube_counter_2 = {key:value for (key, value) in youtube_counter.items() if value >= 3}\n",
    "#final_dict = {x:counter1_2[x] for x in counter1_2 if x in counter2_2}\n",
    "final_dict = {x:[disney_counter_2[x]/disney_num_tokens,\n",
    "                 hbomax_counter_2[x]/hbomax_num_tokens,\n",
    "                 hulu_counter_2[x]/hulu_num_tokens,\n",
    "                 netflix_counter_2[x]/netflix_num_tokens,\n",
    "                 youtube_counter_2[x]/youtube_num_tokens]\\\n",
    "              for x in disney_counter_2 if (x in hbomax_counter_2) & (x in hulu_counter_2) &\\\n",
    "              (x in netflix_counter_2) & (x in youtube_counter_2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Ratios Between All Corpora Combinations and Extract Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kids', 'kid', 'house', 'thank', 'family', 'fun', 'fan', 'older', 'u',\n",
       "       'recommend',\n",
       "       ...\n",
       "       'website', 'title', 'ads', 'connection', 'mode', 'data', 'mobile',\n",
       "       'online', 'downloads', 'offline'],\n",
       "      dtype='object', length=721)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame(final_dict, index = ['disney', 'hbomax', 'hulu', 'netflix', 'youtube'] ).T ####TRANSPOSED!!!!\n",
    "\n",
    "# 10 Possible Comparisons\n",
    "# update: changed some variables named 'new' to 'compare' (was causing an error)\n",
    "\n",
    "compare['disney_v_hbomax'] = compare['disney']/compare['hbomax']\n",
    "compare['disney_v_hulu'] = compare['disney']/compare['hulu']\n",
    "compare['disney_v_netflix'] = compare['disney']/compare['netflix']\n",
    "compare['disney_v_youtube'] = compare['disney']/compare['youtube']\n",
    "\n",
    "compare['hbomax_v_hulu'] = compare['hbomax']/compare['hulu']\n",
    "compare['hbomax_v_netflix'] = compare['hbomax']/compare['netflix']\n",
    "compare['hbomax_v_youtube'] = compare['hbomax']/compare['youtube']\n",
    "\n",
    "compare['hulu_v_netflix'] = compare['hulu']/compare['netflix']\n",
    "compare['hulu_v_youtube'] = compare['hulu']/compare['youtube']\n",
    "\n",
    "compare['netflix_v_youtube'] = compare['netflix']/compare['youtube']\n",
    "\n",
    "#10 Sorted Results\n",
    "disney_v_hbomax = compare.sort_values(by='disney_v_hbomax', ascending=False).index\n",
    "disney_v_hulu = compare.sort_values(by='disney_v_hulu', ascending=False).index\n",
    "disney_v_netflix = compare.sort_values(by='disney_v_netflix', ascending=False).index\n",
    "disney_v_youtube = compare.sort_values(by='disney_v_youtube', ascending=False).index\n",
    "hbomax_v_hulu = compare.sort_values(by='hbomax_v_hulu', ascending=False).index\n",
    "hbomax_v_netflix = compare.sort_values(by='hbomax_v_netflix', ascending=False).index\n",
    "hbomax_v_youtube = compare.sort_values(by='hbomax_v_youtube', ascending=False).index\n",
    "hulu_v_netflix = compare.sort_values(by='hulu_v_netflix', ascending=False).index\n",
    "hulu_v_youtube = compare.sort_values(by='hulu_v_youtube', ascending=False).index\n",
    "netflix_v_youtube = compare.sort_values(by='netflix_v_youtube', ascending=False).index\n",
    "\n",
    "disney_v_hbomax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   disney_v_hbomax disney_v_hulu disney_v_netflix disney_v_youtube  \\\n",
      "0             kids          best          turning         episodes   \n",
      "1              kid        family          channel           movies   \n",
      "2            house         house            short            movie   \n",
      "3            thank           fan             slow          profile   \n",
      "4           family       amazing           create           series   \n",
      "5              fun           kid          freezes              fan   \n",
      "6              fan         world              tap        streaming   \n",
      "7            older          kids             load         password   \n",
      "8                u        thanks              job            shows   \n",
      "9        recommend       believe              fun            email   \n",
      "10       companies           big         friendly          casting   \n",
      "11         channel         thank            speed        subtitles   \n",
      "12         casting        movies          casting             kids   \n",
      "13         missing          star            loads             cast   \n",
      "14        consider          love          version          turning   \n",
      "\n",
      "   hbomax_v_hulu hbomax_v_netflix hbomax_v_youtube hulu_v_netflix  \\\n",
      "0        offline             slow         episodes         minute   \n",
      "1           wifi       downloaded        streaming            ads   \n",
      "2           best          freezes        downloads        freezes   \n",
      "3      connected          offline       downloaded          sound   \n",
      "4        reviews          crashes          offline           adds   \n",
      "5        content        connected           series        minutes   \n",
      "6     downloaded        interface            movie         rewind   \n",
      "7         access          loading           movies        restart   \n",
      "8      downloads       connection       connection        seconds   \n",
      "9       download             load             wifi           load   \n",
      "10      internet          useless        connected           slow   \n",
      "11         offer        downloads      downloading        crashes   \n",
      "12        titles             wifi        selection       messages   \n",
      "13       connect         internet           titles        useless   \n",
      "14       ability            stops            error       constant   \n",
      "\n",
      "   hulu_v_youtube netflix_v_youtube  \n",
      "0        episodes          episodes  \n",
      "1       streaming            series  \n",
      "2         rewatch            movies  \n",
      "3           error             shows  \n",
      "4          rewind           profile  \n",
      "5           shows             movie  \n",
      "6           movie          password  \n",
      "7         casting         canceling  \n",
      "8         freezes         streaming  \n",
      "9       subtitles          canceled  \n",
      "10        restart         subtitles  \n",
      "11          sound             email  \n",
      "12         series            cancel  \n",
      "13          cable           english  \n",
      "14           show              show  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disney_v_hbomax</th>\n",
       "      <th>disney_v_hulu</th>\n",
       "      <th>disney_v_netflix</th>\n",
       "      <th>disney_v_youtube</th>\n",
       "      <th>hbomax_v_hulu</th>\n",
       "      <th>hbomax_v_netflix</th>\n",
       "      <th>hbomax_v_youtube</th>\n",
       "      <th>hulu_v_netflix</th>\n",
       "      <th>hulu_v_youtube</th>\n",
       "      <th>netflix_v_youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>constant</td>\n",
       "      <td>seconds</td>\n",
       "      <td>awful</td>\n",
       "      <td>removed</td>\n",
       "      <td>normal</td>\n",
       "      <td>section</td>\n",
       "      <td>scroll</td>\n",
       "      <td>family</td>\n",
       "      <td>people</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>stops</td>\n",
       "      <td>audio</td>\n",
       "      <td>share</td>\n",
       "      <td>website</td>\n",
       "      <td>history</td>\n",
       "      <td>thank</td>\n",
       "      <td>thank</td>\n",
       "      <td>ask</td>\n",
       "      <td>small</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>awful</td>\n",
       "      <td>starts</td>\n",
       "      <td>lately</td>\n",
       "      <td>previous</td>\n",
       "      <td>ridiculous</td>\n",
       "      <td>bring</td>\n",
       "      <td>interest</td>\n",
       "      <td>added</td>\n",
       "      <td>found</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>downloaded</td>\n",
       "      <td>waste</td>\n",
       "      <td>away</td>\n",
       "      <td>subscribe</td>\n",
       "      <td>pls</td>\n",
       "      <td>kid</td>\n",
       "      <td>seeing</td>\n",
       "      <td>u</td>\n",
       "      <td>bring</td>\n",
       "      <td>tap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>save</td>\n",
       "      <td>close</td>\n",
       "      <td>section</td>\n",
       "      <td>removing</td>\n",
       "      <td>gonna</td>\n",
       "      <td>ones</td>\n",
       "      <td>higher</td>\n",
       "      <td>thanks</td>\n",
       "      <td>features</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>website</td>\n",
       "      <td>minutes</td>\n",
       "      <td>honestly</td>\n",
       "      <td>mode</td>\n",
       "      <td>volume</td>\n",
       "      <td>rated</td>\n",
       "      <td>recommendations</td>\n",
       "      <td>example</td>\n",
       "      <td>scrolling</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>title</td>\n",
       "      <td>ridiculous</td>\n",
       "      <td>yall</td>\n",
       "      <td>mobile</td>\n",
       "      <td>tired</td>\n",
       "      <td>taking</td>\n",
       "      <td>video</td>\n",
       "      <td>ones</td>\n",
       "      <td>best</td>\n",
       "      <td>subscribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>ads</td>\n",
       "      <td>sound</td>\n",
       "      <td>pls</td>\n",
       "      <td>history</td>\n",
       "      <td>casting</td>\n",
       "      <td>guys</td>\n",
       "      <td>adds</td>\n",
       "      <td>removed</td>\n",
       "      <td>information</td>\n",
       "      <td>button</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>connection</td>\n",
       "      <td>rewatch</td>\n",
       "      <td>mobile</td>\n",
       "      <td>save</td>\n",
       "      <td>per</td>\n",
       "      <td>add</td>\n",
       "      <td>side</td>\n",
       "      <td>friends</td>\n",
       "      <td>google</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>mode</td>\n",
       "      <td>mobile</td>\n",
       "      <td>ads</td>\n",
       "      <td>information</td>\n",
       "      <td>sound</td>\n",
       "      <td>removing</td>\n",
       "      <td>u</td>\n",
       "      <td>house</td>\n",
       "      <td>world</td>\n",
       "      <td>scroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>data</td>\n",
       "      <td>volume</td>\n",
       "      <td>website</td>\n",
       "      <td>google</td>\n",
       "      <td>minute</td>\n",
       "      <td>kids</td>\n",
       "      <td>google</td>\n",
       "      <td>bring</td>\n",
       "      <td>channel</td>\n",
       "      <td>minute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>mobile</td>\n",
       "      <td>rewind</td>\n",
       "      <td>took</td>\n",
       "      <td>minute</td>\n",
       "      <td>live</td>\n",
       "      <td>gonna</td>\n",
       "      <td>history</td>\n",
       "      <td>kid</td>\n",
       "      <td>video</td>\n",
       "      <td>ads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>online</td>\n",
       "      <td>adds</td>\n",
       "      <td>taking</td>\n",
       "      <td>video</td>\n",
       "      <td>rewatch</td>\n",
       "      <td>yall</td>\n",
       "      <td>ads</td>\n",
       "      <td>taking</td>\n",
       "      <td>look</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>downloads</td>\n",
       "      <td>minute</td>\n",
       "      <td>removed</td>\n",
       "      <td>videos</td>\n",
       "      <td>adds</td>\n",
       "      <td>u</td>\n",
       "      <td>videos</td>\n",
       "      <td>removing</td>\n",
       "      <td>thanks</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>offline</td>\n",
       "      <td>ads</td>\n",
       "      <td>removing</td>\n",
       "      <td>ads</td>\n",
       "      <td>ads</td>\n",
       "      <td>pls</td>\n",
       "      <td>channel</td>\n",
       "      <td>best</td>\n",
       "      <td>videos</td>\n",
       "      <td>videos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    disney_v_hbomax disney_v_hulu disney_v_netflix disney_v_youtube  \\\n",
       "706        constant       seconds            awful          removed   \n",
       "707           stops         audio            share          website   \n",
       "708           awful        starts           lately         previous   \n",
       "709      downloaded         waste             away        subscribe   \n",
       "710            save         close          section         removing   \n",
       "711         website       minutes         honestly             mode   \n",
       "712           title    ridiculous             yall           mobile   \n",
       "713             ads         sound              pls          history   \n",
       "714      connection       rewatch           mobile             save   \n",
       "715            mode        mobile              ads      information   \n",
       "716            data        volume          website           google   \n",
       "717          mobile        rewind             took           minute   \n",
       "718          online          adds           taking            video   \n",
       "719       downloads        minute          removed           videos   \n",
       "720         offline           ads         removing              ads   \n",
       "\n",
       "    hbomax_v_hulu hbomax_v_netflix hbomax_v_youtube hulu_v_netflix  \\\n",
       "706        normal          section           scroll         family   \n",
       "707       history            thank            thank            ask   \n",
       "708    ridiculous            bring         interest          added   \n",
       "709           pls              kid           seeing              u   \n",
       "710         gonna             ones           higher         thanks   \n",
       "711        volume            rated  recommendations        example   \n",
       "712         tired           taking            video           ones   \n",
       "713       casting             guys             adds        removed   \n",
       "714           per              add             side        friends   \n",
       "715         sound         removing                u          house   \n",
       "716        minute             kids           google          bring   \n",
       "717          live            gonna          history            kid   \n",
       "718       rewatch             yall              ads         taking   \n",
       "719          adds                u           videos       removing   \n",
       "720           ads              pls          channel           best   \n",
       "\n",
       "    hulu_v_youtube netflix_v_youtube  \n",
       "706         people           regular  \n",
       "707          small           current  \n",
       "708          found            google  \n",
       "709          bring               tap  \n",
       "710       features             short  \n",
       "711      scrolling              save  \n",
       "712           best         subscribe  \n",
       "713    information            button  \n",
       "714         google       information  \n",
       "715          world            scroll  \n",
       "716        channel            minute  \n",
       "717          video               ads  \n",
       "718           look             video  \n",
       "719         thanks           channel  \n",
       "720         videos            videos  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = list(zip(disney_v_hbomax, disney_v_hulu, disney_v_netflix, disney_v_youtube, \n",
    "                  hbomax_v_hulu, hbomax_v_netflix, hbomax_v_youtube,\n",
    "                  hulu_v_netflix, hulu_v_youtube,\n",
    "                  netflix_v_youtube))\n",
    "compare2 = pd.DataFrame(zipped, columns=['disney_v_hbomax', 'disney_v_hulu', 'disney_v_netflix', 'disney_v_youtube',\n",
    "                                   'hbomax_v_hulu', 'hbomax_v_netflix', 'hbomax_v_youtube',\n",
    "                                   'hulu_v_netflix', 'hulu_v_youtube',\n",
    "                                   'netflix_v_youtube'])\n",
    "print(compare2.head(15))\n",
    "compare2.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_onlywords</th>\n",
       "      <th>title_onlywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disney</td>\n",
       "      <td>MISSING many shows (and languages)</td>\n",
       "      <td>I grew up watching many a Disney shows. Signed...</td>\n",
       "      <td>3</td>\n",
       "      <td>[grew, watching, many, shows, signed, availabl...</td>\n",
       "      <td>[missing, many, shows, languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disney</td>\n",
       "      <td>really quite upset</td>\n",
       "      <td>pretty sure this was deliberate. my old iphone...</td>\n",
       "      <td>1</td>\n",
       "      <td>[pretty, sure, deliberate, old, iphone, basica...</td>\n",
       "      <td>[really, quite, upset]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disney</td>\n",
       "      <td>Probably the worst streaming app.</td>\n",
       "      <td>We have just about every streaming app you can...</td>\n",
       "      <td>3</td>\n",
       "      <td>[every, streaming, app, think, much, want, one...</td>\n",
       "      <td>[probably, worst, streaming, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disney</td>\n",
       "      <td>Love it but could add more stuff</td>\n",
       "      <td>I live Disney! I grew up with it my whole life...</td>\n",
       "      <td>4</td>\n",
       "      <td>[live, grew, whole, life, dont, know, app, tv,...</td>\n",
       "      <td>[love, could, add, stuff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disney</td>\n",
       "      <td>Frequently causes issues with connectivity</td>\n",
       "      <td>App works great through non-iOS devices but lo...</td>\n",
       "      <td>2</td>\n",
       "      <td>[app, works, great, nonios, devices, locks, ev...</td>\n",
       "      <td>[frequently, causes, issues, connectivity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>By one concern at this time, once you open you...</td>\n",
       "      <td>4</td>\n",
       "      <td>[one, concern, time, open, queue, see, somethi...</td>\n",
       "      <td>[wonderful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Easy on the ads !!!!</td>\n",
       "      <td>Take it easy on the ads Google ! I get it that...</td>\n",
       "      <td>1</td>\n",
       "      <td>[take, easy, ads, google, get, free, service, ...</td>\n",
       "      <td>[easy, ads]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>youtube</td>\n",
       "      <td>You tube outstanding in information dessimination</td>\n",
       "      <td>You tube is outstanding in bringing out idiffe...</td>\n",
       "      <td>5</td>\n",
       "      <td>[outstanding, bringing, idifferent, point, vie...</td>\n",
       "      <td>[outstanding, information, dessimination]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>youtube</td>\n",
       "      <td>It is great for maybe you but for me.</td>\n",
       "      <td>I live somewhere close to the mountains in Cov...</td>\n",
       "      <td>5</td>\n",
       "      <td>[live, somewhere, close, mountains, cove, ariz...</td>\n",
       "      <td>[great, maybe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>youtube</td>\n",
       "      <td>Horrible landscape experience</td>\n",
       "      <td>Revert the horrible change you made to how com...</td>\n",
       "      <td>2</td>\n",
       "      <td>[revert, horrible, change, made, commentsdescr...</td>\n",
       "      <td>[horrible, landscape, experience]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5032 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_name                                              title  \\\n",
       "0      disney                 MISSING many shows (and languages)   \n",
       "1      disney                                 really quite upset   \n",
       "2      disney                  Probably the worst streaming app.   \n",
       "3      disney                   Love it but could add more stuff   \n",
       "4      disney         Frequently causes issues with connectivity   \n",
       "...       ...                                                ...   \n",
       "5027  youtube                                          Wonderful   \n",
       "5028  youtube                               Easy on the ads !!!!   \n",
       "5029  youtube  You tube outstanding in information dessimination   \n",
       "5030  youtube              It is great for maybe you but for me.   \n",
       "5031  youtube                      Horrible landscape experience   \n",
       "\n",
       "                                                 review  rating  \\\n",
       "0     I grew up watching many a Disney shows. Signed...       3   \n",
       "1     pretty sure this was deliberate. my old iphone...       1   \n",
       "2     We have just about every streaming app you can...       3   \n",
       "3     I live Disney! I grew up with it my whole life...       4   \n",
       "4     App works great through non-iOS devices but lo...       2   \n",
       "...                                                 ...     ...   \n",
       "5027  By one concern at this time, once you open you...       4   \n",
       "5028  Take it easy on the ads Google ! I get it that...       1   \n",
       "5029  You tube is outstanding in bringing out idiffe...       5   \n",
       "5030  I live somewhere close to the mountains in Cov...       5   \n",
       "5031  Revert the horrible change you made to how com...       2   \n",
       "\n",
       "                                       review_onlywords  \\\n",
       "0     [grew, watching, many, shows, signed, availabl...   \n",
       "1     [pretty, sure, deliberate, old, iphone, basica...   \n",
       "2     [every, streaming, app, think, much, want, one...   \n",
       "3     [live, grew, whole, life, dont, know, app, tv,...   \n",
       "4     [app, works, great, nonios, devices, locks, ev...   \n",
       "...                                                 ...   \n",
       "5027  [one, concern, time, open, queue, see, somethi...   \n",
       "5028  [take, easy, ads, google, get, free, service, ...   \n",
       "5029  [outstanding, bringing, idifferent, point, vie...   \n",
       "5030  [live, somewhere, close, mountains, cove, ariz...   \n",
       "5031  [revert, horrible, change, made, commentsdescr...   \n",
       "\n",
       "                                 title_onlywords  \n",
       "0              [missing, many, shows, languages]  \n",
       "1                         [really, quite, upset]  \n",
       "2              [probably, worst, streaming, app]  \n",
       "3                      [love, could, add, stuff]  \n",
       "4     [frequently, causes, issues, connectivity]  \n",
       "...                                          ...  \n",
       "5027                                 [wonderful]  \n",
       "5028                                 [easy, ads]  \n",
       "5029   [outstanding, information, dessimination]  \n",
       "5030                              [great, maybe]  \n",
       "5031           [horrible, landscape, experience]  \n",
       "\n",
       "[5032 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with DF and Lists: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i grew up watching many a disney shows signed up for disney most of them are not available the ones that are not available in my language or a decent selection at all ebglish and spanish only reallythere are official dubs that were aired on public television decades ago already and disney only has english for most of the shows if they are even on there to watch at least they finally have the clone wars magnificent animation as always tartakovsky is magnificent but i had to wait for that as well the app will crashfreeze if you hit the rewind button too often not for people that like watching specific scenes again and again and there is no option to either loop a video yes i would like to have biomes and vehicle on in the background while i worksleep or to make it stop asking ‚Äúare you still there‚Äù so at some point it will stop playing and if you have loud neighbors throwing on dinsney to tune them out whilst you sleep is not an option the quality of the videos themselves is top notch though volume could be louder but visuals are great but seriously why own the rights to all these shows and not let people see them or make them available anywhere else i want my nostalgic throwback to before 3 stars because they‚Äôre sitting on the content they own and deriving people of content that used to be readily available decades ago used to be with basic cable for free and now you get to pay and not see them',\n",
       "  'disney'],\n",
       " ['pretty sure this was deliberate my old iphone6 is basically dead unfortunately it was the phone i was using when i signed up for disney now i need to change the email attached to the account and i cant do that unless they email me a passcode the customer service person sent the passcode rejected error 21 they sent another one no good so they sent another one except it was the same as the first this was of course after they logged out all of my devices so i am now unable to use the service i have already paid for this is only a couple of months after i had to argue with them for hours to reset the password after a previous involuntary logout disney did to us that ended up with a like 50 character password i had to draw out on graphing paper cause my handwriting is garbage since i started typing everything which isnt here or there but what is pertinent is im like 99 sure theyre doing this because my voice is horribly deep so they know im trans theyre already working on exterminating us and now i have nothing to watch while i wait for the new american fascism to put us all into camps \\nhonestly did not care about cutting netflix when they decided to stand up for transphobic comedians have no problem responding to warner bros insistance on supporting jk by cancelling hbomax now disneywho granted seem to want to ignore our existence completely im losing my superheros and im sincerely depressed by it whatever goodbye disney',\n",
       "  'disney'],\n",
       " ['we have just about every streaming app you can think of and as much as i want this one to be my favorite its definitely the worst and the most unreliable we use disney every single day since we have littles that need to watch encanto on a constant loop however myself and my husband are huge marvel fans so we use it just as much as the kids do \\n\\nmy kids lost the remote to our tv last week and i have stripped this house bare trying to find it and cant so we have been relying on screen mirroring and casting disney is the only app that we have that refuses to work \\n\\nwhen we did have our tv remote and could use disney it would always about every 30 minutes kick us out and tell us our internet was working so we would just exit the app and go back in and it would be fine we just moved into a new home and i was hoping the connection with the app would be better nope it still times out about every 30 minutes and tells us there no internet connection when everything else in our house is working just fine basically when this happens you would have to exit the app then return and if might start to work the only reason i havent deleted this app already is because my daughter has to watch mickey mouse clubhouse',\n",
       "  'disney'],\n",
       " ['i live disney i grew up with it my whole life but i don‚Äôt know if it‚Äôs the app or my tv or my phone because i‚Äôm getting frustrated because i wanted to watch tangled with my family but the controller ran out of battery and it was about 1028 at the time and if we went to the store at that time it would be closed the time we got there so we had to just use it threw our phones first my sister tried it didn‚Äôt work then i tried it also didn‚Äôt work \\nat this point i was getting a little frustrated because there was no other app that had tangled on there so we tried 1 more time but it didn‚Äôt work we used the connect to tv button also multiple times it said we had to fix something in settings so we went to settings and we couldn‚Äôt find anything related to disney usually it would take us straight to where we need to go and what to do but no nothing worked so disney please fix this problem but other than that the app is amazing it is perfect for kids and disney lovers it has all the disney movies created and there is not 1 movie you can‚Äôt think of that‚Äôs not there but disney please fix this problem i would like it if you do',\n",
       "  'disney'],\n",
       " ['app works great through nonios devices but locks up about every 2040 minutes on iphone or ipad not just the app itself but most other apps lose connection to their servers as a result despite that several speed tests show the device is still well connected to wan doesn‚Äôt happen with any other apps and is consistent across multiple devices i‚Äôd suggest the devs look into how disney handles data traffic on ios because having to turn wifi off and on several times an hour is simply aggravating \\n    also regardless of connectivity‚Ä¶ it would be an absolutely smashing idea to make it easier to access the main menu for recentlywatched series ie the page that lets you select seasons and browse episodes i‚Äôm sure it‚Äôs either an oversight or perhaps too difficult to implement basic infrastructure changes but so far users only have the option to restart the last series episode from the home page and exiting with the ‚Äú‚Äú option at top left just brings you back to home wouldn‚Äôt it be especially nice to not have to click through multiple menus to find the series you were watching for me it may have been seconds ago every single time you use the app aka what customers should and do expect',\n",
       "  'disney']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortdb = pd.DataFrame(df, columns = ['review', 'app_name'])\n",
    "shortlist = shortdb.values.tolist()\n",
    "shortlist = [[t.translate(str.maketrans('', '', string.punctuation)),p] for t, p in shortlist]\n",
    "shortlist = [[t.lower(),p] for t, p in shortlist]\n",
    "shortlist[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce a Word Cut-Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'grew', 'up', 'watching', 'many']\n",
      "With a word cutoff of 5, we have 2959 features in the model.\n"
     ]
    }
   ],
   "source": [
    "##### INTRODUCE A WORD CUT-OFF\n",
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in shortlist for w in t.split()]\n",
    "print(tokens[0:5])\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "#for w, c in word_dist.items():\n",
    "#    print(w, c)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} features in the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ret_dict = dict()\n",
    "# tokenize each piece of text into text_tokens\n",
    "# for token in text_tokens if in fw:\n",
    "# add token and True to a dictionary\n",
    "# return(ret_dict)\n",
    "\n",
    "def conv_features(review,fw):\n",
    "    #ret_list = []\n",
    "    ret_dict = dict()\n",
    "    #text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    #text = text.lower()\n",
    "    review = [w for w in review.split() if w not in (set(sw))]\n",
    "    \n",
    "    for token in fw:\n",
    "        if token in review:\n",
    "            ret_dict.update({token: 1})\n",
    "        else:\n",
    "            ret_dict.update({token: 0})\n",
    "\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(review,feature_words), app_name) for (review, app_name) in shortlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.seed(20220507)\n",
    "random.seed(84)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1: NB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disney', 'hbomax', 'hulu', 'netflix', 'youtube']\n",
      "0.746\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(sorted(classifier.labels()))\n",
    "#print(classifier.labels())\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 episode = 1              hbomax : youtub =     93.8 : 1.0\n",
      "                  season = 1              netfli : youtub =     70.9 : 1.0\n",
      "                     ads = 1                hulu : disney =     64.9 : 1.0\n",
      "                  videos = 1              youtub : netfli =     57.6 : 1.0\n",
      "                 seasons = 1              netfli : youtub =     56.5 : 1.0\n",
      "                   buggy = 1              hbomax : youtub =     56.1 : 1.0\n",
      "             commercials = 1                hulu : disney =     54.9 : 1.0\n",
      "                comments = 1              youtub : hulu   =     53.8 : 1.0\n",
      "                   music = 1              youtub : hulu   =     41.5 : 1.0\n",
      "                  minute = 1                hulu : netfli =     38.0 : 1.0\n",
      "                 comment = 1              youtub : hulu   =     35.7 : 1.0\n",
      "                children = 1              disney : hulu   =     34.2 : 1.0\n",
      "                  flight = 1              hbomax : netfli =     32.2 : 1.0\n",
      "               streaming = 1              hbomax : youtub =     31.2 : 1.0\n",
      "                creators = 1              youtub : disney =     30.8 : 1.0\n",
      "                 offline = 1              hbomax : youtub =     29.7 : 1.0\n",
      "                episodes = 1              hbomax : youtub =     28.5 : 1.0\n",
      "                 channel = 1              youtub : netfli =     28.2 : 1.0\n",
      "                   video = 1              youtub : disney =     28.1 : 1.0\n",
      "                    teen = 1              netfli : hulu   =     26.1 : 1.0\n",
      "                playlist = 1              youtub : hulu   =     26.1 : 1.0\n",
      "                   anime = 1              netfli : disney =     25.8 : 1.0\n",
      "                 viewing = 1              hbomax : disney =     25.6 : 1.0\n",
      "                   plane = 1              hbomax : youtub =     24.8 : 1.0\n",
      "                removing = 1              netfli : disney =     24.5 : 1.0\n",
      "                   movie = 1              disney : youtub =     24.2 : 1.0\n",
      "                     rid = 1              netfli : disney =     23.8 : 1.0\n",
      "                cellular = 1              hbomax : youtub =     23.4 : 1.0\n",
      "                 dislike = 1              youtub : hbomax =     23.1 : 1.0\n",
      "                provider = 1              hbomax : youtub =     22.7 : 1.0\n",
      "                   taken = 1              netfli : hulu   =     22.2 : 1.0\n",
      "                   crash = 1              hbomax : netfli =     22.1 : 1.0\n",
      "                    post = 1              youtub : netfli =     21.7 : 1.0\n",
      "              downloaded = 1              hbomax : netfli =     21.4 : 1.0\n",
      "                crashing = 1              hbomax : netfli =     21.4 : 1.0\n",
      "                stranger = 1              netfli : youtub =     20.9 : 1.0\n",
      "                 diaries = 1              netfli : hulu   =     20.8 : 1.0\n",
      "                  travel = 1              hbomax : hulu   =     20.5 : 1.0\n",
      "                  series = 1              netfli : youtub =     20.4 : 1.0\n",
      "                 glitchy = 1              hbomax : youtub =     19.9 : 1.0\n",
      "                  movies = 1              disney : youtub =     19.0 : 1.0\n",
      "               downloads = 1              hbomax : youtub =     18.7 : 1.0\n",
      "               listening = 1              youtub : disney =     18.7 : 1.0\n",
      "                  prices = 1              netfli : youtub =     18.2 : 1.0\n",
      "               connected = 1              hbomax : netfli =     17.7 : 1.0\n",
      "                      ad = 1                hulu : netfli =     17.7 : 1.0\n",
      "                    slow = 1              hbomax : netfli =     17.6 : 1.0\n",
      "                   upset = 1              netfli : hbomax =     17.4 : 1.0\n",
      "              restarting = 1              hbomax : netfli =     17.3 : 1.0\n",
      "                 crashes = 1              hbomax : netfli =     16.9 : 1.0\n",
      "                  freeze = 1              hbomax : disney =     16.9 : 1.0\n",
      "                    wars = 1              disney : netfli =     16.7 : 1.0\n",
      "                channels = 1              youtub : hbomax =     16.6 : 1.0\n",
      "                freezing = 1              hbomax : netfli =     16.6 : 1.0\n",
      "                    paid = 1              hbomax : netfli =     16.6 : 1.0\n",
      "           inappropriate = 1              youtub : hulu   =     16.4 : 1.0\n",
      "                  listen = 1              youtub : hulu   =     16.4 : 1.0\n",
      "                  titles = 1              hbomax : youtub =     16.4 : 1.0\n",
      "             recommended = 1              youtub : hbomax =     16.3 : 1.0\n",
      "               originals = 1              netfli : hulu   =     16.2 : 1.0\n",
      "                criminal = 1              netfli : youtub =     16.1 : 1.0\n",
      "                 vampire = 1              netfli : hulu   =     15.3 : 1.0\n",
      "                 attempt = 1              hbomax : netfli =     15.3 : 1.0\n",
      "                playback = 1              hbomax : netfli =     15.3 : 1.0\n",
      "                    song = 1              youtub : netfli =     15.2 : 1.0\n",
      "                   shows = 1              netfli : youtub =     15.2 : 1.0\n",
      "                 profile = 1              netfli : youtub =     15.0 : 1.0\n",
      "                   minds = 1              netfli : disney =     14.7 : 1.0\n",
      "                   tells = 1              hbomax : youtub =     14.3 : 1.0\n",
      "               youtubers = 1              youtub : disney =     14.3 : 1.0\n",
      "                     mad = 1              netfli : hbomax =     14.1 : 1.0\n",
      "                airplane = 1              hbomax : netfli =     14.0 : 1.0\n",
      "               buffering = 1              hbomax : netfli =     13.9 : 1.0\n",
      "                    news = 1              youtub : hulu   =     13.8 : 1.0\n",
      "                     tab = 1              youtub : disney =     13.6 : 1.0\n",
      "              connection = 1              hbomax : youtub =     13.6 : 1.0\n",
      "                   login = 1              hbomax : youtub =     13.6 : 1.0\n",
      "                accounts = 1              netfli : hulu   =     13.6 : 1.0\n",
      "                 encanto = 1              disney : netfli =     13.3 : 1.0\n",
      "                     red = 1              disney : netfli =     13.3 : 1.0\n",
      "                    luck = 1              hbomax : netfli =     13.2 : 1.0\n",
      "                 freezes = 1              hbomax : netfli =     13.2 : 1.0\n",
      "                   learn = 1              youtub : hulu   =     13.2 : 1.0\n",
      "                  useful = 1              youtub : hulu   =     13.2 : 1.0\n",
      "             downloading = 1              hbomax : youtub =     13.0 : 1.0\n",
      "                   skips = 1              hbomax : disney =     12.9 : 1.0\n",
      "                  launch = 1              hbomax : youtub =     12.9 : 1.0\n",
      "                    roku = 1              hbomax : youtub =     12.9 : 1.0\n",
      "                   error = 1              hbomax : youtub =     12.8 : 1.0\n",
      "                    girl = 1              netfli : hbomax =     12.8 : 1.0\n",
      "               cancelled = 1              netfli : youtub =     12.7 : 1.0\n",
      "               community = 1              youtub : hulu   =     12.6 : 1.0\n",
      "                    dots = 1              hbomax : hulu   =     12.5 : 1.0\n",
      "                  shorts = 1              youtub : disney =     12.4 : 1.0\n",
      "                    wifi = 1              hbomax : hulu   =     12.3 : 1.0\n",
      "                    trip = 1              hbomax : youtub =     12.2 : 1.0\n",
      "                    best = 1              netfli : hulu   =     12.2 : 1.0\n",
      "             subscribers = 1              netfli : disney =     12.1 : 1.0\n",
      "                  animes = 1              netfli : youtub =     12.0 : 1.0\n",
      "                   child = 1              disney : hulu   =     11.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "# print(sorted(dt_classifier.labels()))\n",
    "# #print(classifier.labels())\n",
    "# print(nltk.classify.accuracy(dt_classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2: SklearnClassifiers: LinearSVC (SVM), BernoulliNB,  LogisticRegression, SGD, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disney', 'hbomax', 'hulu', 'netflix', 'youtube']\n",
      "0.684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svc_classif = SklearnClassifier(LinearSVC(dual=False)).train(train_set)\n",
    "print(sorted(svc_classif.labels()))\n",
    "print(nltk.classify.accuracy(svc_classif, test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disney', 'hbomax', 'hulu', 'netflix', 'youtube']\n",
      "0.732\n"
     ]
    }
   ],
   "source": [
    "bnb_classif = SklearnClassifier(BernoulliNB()).train(train_set)\n",
    "print(sorted(bnb_classif.labels()))\n",
    "print(nltk.classify.accuracy(bnb_classif, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disney', 'hbomax', 'hulu', 'netflix', 'youtube']\n",
      "0.718\n"
     ]
    }
   ],
   "source": [
    "logreg_classif = SklearnClassifier(LogisticRegression(solver='liblinear')).train(train_set)\n",
    "print(sorted(logreg_classif.labels()))\n",
    "print(nltk.classify.accuracy(logreg_classif, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disney', 'hbomax', 'hulu', 'netflix', 'youtube']\n",
      "0.668\n"
     ]
    }
   ],
   "source": [
    "sgd_classif = SklearnClassifier(SGDClassifier()).train(train_set)\n",
    "print(sorted(sgd_classif.labels()))\n",
    "print(nltk.classify.accuracy(sgd_classif, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disney', 'hbomax', 'hulu', 'netflix', 'youtube']\n",
      "0.716\n"
     ]
    }
   ],
   "source": [
    "nusvc_classif = SklearnClassifier(NuSVC()).train(train_set)\n",
    "print(sorted(nusvc_classif.labels()))\n",
    "print(nltk.classify.accuracy(nusvc_classif, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Topic Modeling: Non-Negative Matrix Factorization (NMF) Model with CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function comes from the BTAP repo.\n",
    "\n",
    "def display_topics(model, features, no_top_words=10):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5032, 2941)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "\n",
    "count_text_vectorizer = CountVectorizer(stop_words=sw, min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df[\"review\"])\n",
    "count_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1080p</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youtuber</th>\n",
       "      <th>youtubers</th>\n",
       "      <th>yt</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 2941 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  10  100  1000  1080p  11  12  13  14  ...  yesterday  yet  young  \\\n",
       "0   0    0   0    0     0      0   0   0   0   0  ...          0    0      0   \n",
       "1   0    0   0    0     0      0   0   0   0   0  ...          0    0      0   \n",
       "2   0    0   0    0     0      0   0   0   0   0  ...          0    0      0   \n",
       "3   0    0   1    0     0      0   0   0   0   0  ...          0    0      0   \n",
       "4   0    0   0    0     0      0   0   0   0   0  ...          0    0      0   \n",
       "\n",
       "   younger  youtuber  youtubers  yt  zero  zombies  zoom  \n",
       "0        0         0          0   0     0        0     0  \n",
       "1        0         0          0   0     0        0     0  \n",
       "2        0         0          0   0     0        0     0  \n",
       "3        0         0          0   0     0        0     0  \n",
       "4        0         0          0   0     0        0     0  \n",
       "\n",
       "[5 rows x 2941 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = count_text_vectorizer.get_feature_names_out()\n",
    "\n",
    "df_count_text = pd.DataFrame.sparse.from_spmatrix(count_text_vectors, columns=feat_names)\n",
    "\n",
    "df_count_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_count_text_model = NMF(n_components=5, random_state=314)\n",
    "\n",
    "W_text_matrix = nmf_count_text_model.fit_transform(count_text_vectors)\n",
    "\n",
    "H_text_matrix = nmf_count_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  app (10.92)\n",
      "  content (1.20)\n",
      "  download (1.06)\n",
      "  time (1.02)\n",
      "  tv (0.89)\n",
      "  work (0.84)\n",
      "  use (0.83)\n",
      "  even (0.81)\n",
      "  streaming (0.79)\n",
      "  fix (0.79)\n",
      "\n",
      "Topic 01\n",
      "  watch (11.34)\n",
      "  show (3.84)\n",
      "  movie (1.53)\n",
      "  time (1.46)\n",
      "  tv (1.44)\n",
      "  episode (1.40)\n",
      "  want (1.35)\n",
      "  watching (1.34)\n",
      "  even (1.12)\n",
      "  something (0.95)\n",
      "\n",
      "Topic 02\n",
      "  video (3.65)\n",
      "  ads (3.42)\n",
      "  videos (2.35)\n",
      "  get (1.86)\n",
      "  ad (1.41)\n",
      "  one (0.94)\n",
      "  even (0.90)\n",
      "  back (0.88)\n",
      "  time (0.78)\n",
      "  watching (0.72)\n",
      "\n",
      "Topic 03\n",
      "  like (5.56)\n",
      "  shows (5.52)\n",
      "  movies (2.56)\n",
      "  good (2.14)\n",
      "  love (1.50)\n",
      "  really (1.42)\n",
      "  would (1.19)\n",
      "  one (1.11)\n",
      "  people (1.06)\n",
      "  great (0.97)\n",
      "\n",
      "Topic 04\n",
      "  please (14.96)\n",
      "  add (3.08)\n",
      "  love (2.82)\n",
      "  back (2.73)\n",
      "  fix (2.33)\n",
      "  really (1.21)\n",
      "  make (1.07)\n",
      "  thank (1.03)\n",
      "  delete (0.94)\n",
      "  show (0.93)\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_count_text_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic  app_name\n",
       "0      disney      293\n",
       "       hbomax      561\n",
       "       hulu        301\n",
       "       netflix     124\n",
       "       youtube     154\n",
       "1      disney      223\n",
       "       hbomax      216\n",
       "       hulu        245\n",
       "       netflix     212\n",
       "       youtube      79\n",
       "2      disney       82\n",
       "       hbomax       75\n",
       "       hulu        293\n",
       "       netflix      69\n",
       "       youtube     577\n",
       "3      disney      303\n",
       "       hbomax      104\n",
       "       hulu        104\n",
       "       netflix     410\n",
       "       youtube     112\n",
       "4      disney      107\n",
       "       hbomax       45\n",
       "       hulu         57\n",
       "       netflix     189\n",
       "       youtube      97\n",
       "Name: app_name, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new DF that adds NMF topic scores to original data including app name and rating\n",
    "df_NMF = pd.concat([df[['app_name', 'rating']], pd.DataFrame(W_text_matrix)], axis=1)\n",
    "\n",
    "# Add Topic column = highest topic score\n",
    "df_NMF['Topic'] = df_NMF[[0,1,2,3,4]].idxmax(axis=1)\n",
    "\n",
    "#Group by Topic, then app name and count the number of app_names per topic\n",
    "df_NMF.groupby(['Topic','app_name'])['app_name'].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  rating\n",
      "0      1         574\n",
      "       2         325\n",
      "       3         182\n",
      "       4         146\n",
      "       5         206\n",
      "1      1         294\n",
      "       2         166\n",
      "       3         158\n",
      "       4         147\n",
      "       5         210\n",
      "2      1         327\n",
      "       2         163\n",
      "       3         196\n",
      "       4         185\n",
      "       5         225\n",
      "3      1         202\n",
      "       2         116\n",
      "       3         141\n",
      "       4         209\n",
      "       5         365\n",
      "4      1          67\n",
      "       2          42\n",
      "       3          76\n",
      "       4         143\n",
      "       5         167\n",
      "Name: app_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Group by Topic, then rating and count the number of occurrences of each rating per topic\n",
    "NMF_map = df_NMF.groupby(['Topic','rating'])['app_name'].count()\n",
    "\n",
    "print(str(NMF_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Topic Modeling: Non-Negative Matrix Factorization (NMF) Model with TF-IDF Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5032, 2941)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF  Vectorizer\n",
    "\n",
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=sw, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df[\"review\"])\n",
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1080p</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youtuber</th>\n",
       "      <th>youtubers</th>\n",
       "      <th>yt</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 2941 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000        10  100  1000  1080p   11   12   13   14  ...  yesterday  \\\n",
       "0  0.0  0.0  0.000000  0.0   0.0    0.0  0.0  0.0  0.0  0.0  ...        0.0   \n",
       "1  0.0  0.0  0.000000  0.0   0.0    0.0  0.0  0.0  0.0  0.0  ...        0.0   \n",
       "2  0.0  0.0  0.000000  0.0   0.0    0.0  0.0  0.0  0.0  0.0  ...        0.0   \n",
       "3  0.0  0.0  0.090144  0.0   0.0    0.0  0.0  0.0  0.0  0.0  ...        0.0   \n",
       "4  0.0  0.0  0.000000  0.0   0.0    0.0  0.0  0.0  0.0  0.0  ...        0.0   \n",
       "\n",
       "   yet  young  younger  youtuber  youtubers   yt  zero  zombies  zoom  \n",
       "0  0.0    0.0      0.0       0.0        0.0  0.0   0.0      0.0   0.0  \n",
       "1  0.0    0.0      0.0       0.0        0.0  0.0   0.0      0.0   0.0  \n",
       "2  0.0    0.0      0.0       0.0        0.0  0.0   0.0      0.0   0.0  \n",
       "3  0.0    0.0      0.0       0.0        0.0  0.0   0.0      0.0   0.0  \n",
       "4  0.0    0.0      0.0       0.0        0.0  0.0   0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 2941 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = tfidf_text_vectorizer.get_feature_names_out()\n",
    "\n",
    "df_tfidf_text = pd.DataFrame.sparse.from_spmatrix(tfidf_text_vectors, columns=feat_names)\n",
    "\n",
    "df_tfidf_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_tfidf_text_model = NMF(n_components=5, random_state=314)\n",
    "\n",
    "W_text_matrix2 = nmf_tfidf_text_model.fit_transform(tfidf_text_vectors)\n",
    "\n",
    "H_text_matrix2 = nmf_tfidf_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  app (3.11)\n",
      "  download (1.12)\n",
      "  content (0.92)\n",
      "  work (0.86)\n",
      "  time (0.80)\n",
      "  downloaded (0.76)\n",
      "  phone (0.72)\n",
      "  streaming (0.69)\n",
      "  even (0.68)\n",
      "  tv (0.66)\n",
      "\n",
      "Topic 01\n",
      "  shows (2.63)\n",
      "  movies (2.23)\n",
      "  like (1.90)\n",
      "  love (1.90)\n",
      "  watch (1.49)\n",
      "  good (1.41)\n",
      "  really (1.21)\n",
      "  please (1.00)\n",
      "  would (0.91)\n",
      "  add (0.86)\n",
      "\n",
      "Topic 02\n",
      "  ads (11.36)\n",
      "  ad (2.78)\n",
      "  watch (1.95)\n",
      "  minutes (1.64)\n",
      "  minute (1.63)\n",
      "  pay (1.45)\n",
      "  many (1.24)\n",
      "  seconds (1.08)\n",
      "  get (1.04)\n",
      "  paying (0.95)\n",
      "\n",
      "Topic 03\n",
      "  video (3.15)\n",
      "  videos (2.30)\n",
      "  please (0.98)\n",
      "  screen (0.84)\n",
      "  back (0.80)\n",
      "  like (0.76)\n",
      "  see (0.75)\n",
      "  button (0.68)\n",
      "  want (0.64)\n",
      "  fix (0.63)\n",
      "\n",
      "Topic 04\n",
      "  episode (4.38)\n",
      "  show (3.52)\n",
      "  watching (2.06)\n",
      "  next (2.00)\n",
      "  episodes (1.81)\n",
      "  play (1.59)\n",
      "  back (1.23)\n",
      "  go (1.14)\n",
      "  tv (0.95)\n",
      "  watch (0.90)\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_tfidf_text_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic  app_name\n",
       "0      disney      293\n",
       "       hbomax      561\n",
       "       hulu        301\n",
       "       netflix     124\n",
       "       youtube     154\n",
       "1      disney      223\n",
       "       hbomax      216\n",
       "       hulu        245\n",
       "       netflix     212\n",
       "       youtube      79\n",
       "2      disney       82\n",
       "       hbomax       75\n",
       "       hulu        293\n",
       "       netflix      69\n",
       "       youtube     577\n",
       "3      disney      303\n",
       "       hbomax      104\n",
       "       hulu        104\n",
       "       netflix     410\n",
       "       youtube     112\n",
       "4      disney      107\n",
       "       hbomax       45\n",
       "       hulu         57\n",
       "       netflix     189\n",
       "       youtube      97\n",
       "Name: app_name, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new DF that adds NMF topic scores to original data including app name and rating\n",
    "df_NMF_tdif = pd.concat([df[['app_name', 'rating']], pd.DataFrame(W_text_matrix2)], axis=1)\n",
    "\n",
    "# Add Topic column = highest topic score\n",
    "df_NMF['Topic'] = df_NMF[[0,1,2,3,4]].idxmax(axis=1)\n",
    "\n",
    "#Group by Topic, then app name and count the number of app_names per topic\n",
    "df_NMF.groupby(['Topic','app_name'])['app_name'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Topic Modeling: Latent Semantic Analysis (LSA) Model with TF-IDF Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA Model\n",
    "\n",
    "svd_para_model = TruncatedSVD(n_components = 5, random_state=314)\n",
    "W_svd_para_matrix = svd_para_model.fit_transform(tfidf_text_vectors)\n",
    "H_svd_para_matrix = svd_para_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  app (1.39)\n",
      "  watch (0.96)\n",
      "  shows (0.82)\n",
      "  like (0.73)\n",
      "  show (0.62)\n",
      "  movies (0.61)\n",
      "  love (0.57)\n",
      "  get (0.55)\n",
      "  time (0.52)\n",
      "  ads (0.52)\n",
      "\n",
      "Topic 01\n",
      "  shows (12.60)\n",
      "  movies (10.90)\n",
      "  like (9.97)\n",
      "  love (9.86)\n",
      "  good (6.83)\n",
      "  add (6.40)\n",
      "  please (5.94)\n",
      "  really (5.92)\n",
      "  favorite (3.83)\n",
      "  people (3.82)\n",
      "\n",
      "Topic 02\n",
      "  ads (258.23)\n",
      "  ad (76.32)\n",
      "  video (49.85)\n",
      "  minutes (39.69)\n",
      "  minute (38.39)\n",
      "  seconds (29.05)\n",
      "  videos (27.39)\n",
      "  annoying (27.09)\n",
      "  pay (26.64)\n",
      "  watch (25.42)\n",
      "\n",
      "Topic 03\n",
      "  shows (4.83)\n",
      "  movies (4.15)\n",
      "  ads (4.07)\n",
      "  watch (2.91)\n",
      "  download (2.42)\n",
      "  downloaded (1.72)\n",
      "  app (1.64)\n",
      "  tv (1.39)\n",
      "  internet (1.29)\n",
      "  streaming (1.11)\n",
      "\n",
      "Topic 04\n",
      "  episode (17.79)\n",
      "  show (15.73)\n",
      "  episodes (8.33)\n",
      "  next (7.83)\n",
      "  watching (7.62)\n",
      "  please (6.32)\n",
      "  back (5.20)\n",
      "  season (5.14)\n",
      "  play (5.06)\n",
      "  movie (3.71)\n"
     ]
    }
   ],
   "source": [
    "display_topics(svd_para_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic  app_name\n",
       "0      disney      890\n",
       "       hbomax      976\n",
       "       hulu        751\n",
       "       netflix     896\n",
       "       youtube     925\n",
       "1      disney       71\n",
       "       hbomax        1\n",
       "       hulu          4\n",
       "       netflix      81\n",
       "       youtube       3\n",
       "2      disney        1\n",
       "       hbomax        4\n",
       "       hulu        206\n",
       "       netflix       2\n",
       "       youtube      91\n",
       "3      disney        4\n",
       "       hbomax        1\n",
       "       hulu          2\n",
       "       netflix       1\n",
       "4      disney       42\n",
       "       hbomax       19\n",
       "       hulu         37\n",
       "       netflix      24\n",
       "Name: app_name, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new DF that adds NMF topic scores to original data including app name and rating\n",
    "df_LSA = pd.concat([df[['app_name', 'rating']], pd.DataFrame(W_svd_para_matrix)], axis=1)\n",
    "\n",
    "# Add Topic column = highest topic score\n",
    "df_LSA['Topic'] = df_LSA[[0,1,2,3,4]].idxmax(axis=1)\n",
    "\n",
    "#Group by Topic, then app name and count the number of app_names per topic\n",
    "df_LSA.groupby(['Topic','app_name'])['app_name'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Topic Modeling: Latent Dirichlet Allocation (LDA) Model with TF-IDF Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Model\n",
    "\n",
    "lda_para_model = LatentDirichletAllocation(n_components = 5, random_state=314)\n",
    "W_lda_para_matrix = lda_para_model.fit_transform(count_text_vectors)\n",
    "H_lda_para_matrix = lda_para_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  video (3.06)\n",
      "  videos (2.36)\n",
      "  app (1.34)\n",
      "  like (1.30)\n",
      "  screen (1.02)\n",
      "  please (0.96)\n",
      "  back (0.87)\n",
      "  want (0.86)\n",
      "  see (0.86)\n",
      "  watch (0.85)\n",
      "\n",
      "Topic 01\n",
      "  app (5.34)\n",
      "  tv (1.15)\n",
      "  update (1.03)\n",
      "  service (1.02)\n",
      "  phone (1.01)\n",
      "  work (1.00)\n",
      "  get (0.99)\n",
      "  even (0.98)\n",
      "  time (0.90)\n",
      "  fix (0.88)\n",
      "\n",
      "Topic 02\n",
      "  app (4.49)\n",
      "  watch (2.60)\n",
      "  show (1.85)\n",
      "  ads (1.62)\n",
      "  episode (1.56)\n",
      "  download (1.36)\n",
      "  shows (1.29)\n",
      "  time (1.21)\n",
      "  watching (1.20)\n",
      "  play (1.03)\n",
      "\n",
      "Topic 03\n",
      "  content (1.82)\n",
      "  app (1.42)\n",
      "  people (0.92)\n",
      "  many (0.74)\n",
      "  like (0.73)\n",
      "  money (0.57)\n",
      "  way (0.52)\n",
      "  well (0.51)\n",
      "  one (0.49)\n",
      "  much (0.48)\n",
      "\n",
      "Topic 04\n",
      "  shows (2.93)\n",
      "  like (2.74)\n",
      "  watch (2.23)\n",
      "  love (2.02)\n",
      "  movies (1.98)\n",
      "  app (1.70)\n",
      "  please (1.53)\n",
      "  good (1.46)\n",
      "  show (1.26)\n",
      "  really (1.25)\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda_para_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic  app_name\n",
       "0      disney      890\n",
       "       hbomax      976\n",
       "       hulu        751\n",
       "       netflix     896\n",
       "       youtube     925\n",
       "1      disney       71\n",
       "       hbomax        1\n",
       "       hulu          4\n",
       "       netflix      81\n",
       "       youtube       3\n",
       "2      disney        1\n",
       "       hbomax        4\n",
       "       hulu        206\n",
       "       netflix       2\n",
       "       youtube      91\n",
       "3      disney        4\n",
       "       hbomax        1\n",
       "       hulu          2\n",
       "       netflix       1\n",
       "4      disney       42\n",
       "       hbomax       19\n",
       "       hulu         37\n",
       "       netflix      24\n",
       "Name: app_name, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new DF that adds NMF topic scores to original data including app name and rating\n",
    "df_LDA = pd.concat([df[['app_name', 'rating']], pd.DataFrame(W_lda_para_matrix)], axis=1)\n",
    "\n",
    "# Add Topic column = highest topic score\n",
    "df_LDA['Topic'] = df_LSA[[0,1,2,3,4]].idxmax(axis=1)\n",
    "\n",
    "#Group by Topic, then app name and count the number of app_names per topic\n",
    "df_LDA.groupby(['Topic','app_name'])['app_name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
